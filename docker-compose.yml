version: '3.8'
services:
  llm:
    image: litellm/ollama:latest
    entrypoint: ["/bin/bash", "-c", "ollama serve & litellm --model ollama/${LOCAL_LLM_MODEL} --host 0.0.0.0 --port 5001"]
    ports:
      - "${LOCAL_LLM_PORT}:5001"

  backend:
    build: ./backend
    ports:
      - "${BACKEND_PORT}:8000"
    volumes:
      - ./backend:/app
    depends_on:
      - llm
    environment:
      - LOCAL_LLM_API_ENDPOINT=http://llm:5001
      - OPENAI_LLM_API_KEY=${OPENAI_LLM_API_KEY}
      - OPENAI_LLM_API_ENDPOINT=${OPENAI_LLM_API_ENDPOINT}

  frontend:
    build: ./frontend
    ports:
      - "${FRONTEND_PORT}:8501"
    volumes:
      - ./frontend:/app
    depends_on:
      - backend
    environment:
      - BACKEND_ENDPOINT=http://backend:8000

#   db:
#     image: postgres:latest
#     environment:
#       POSTGRES_DB: yourdbname
#       POSTGRES_USER: yourdbuser
#       POSTGRES_PASSWORD: yourdbpassword
#     volumes:
#       - postgres_data:/var/lib/postgresql/data

# volumes:
#   postgres_data:
