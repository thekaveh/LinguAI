version: "3.8"
services:
  ollama:
    build: ./ollama
    ports:
      - "${OLLAMA_PORT}:11434"
    env_file:
      - .env # This will pass all .env variables into the container
    environment:
      NVIDIA_VISIBLE_DEVICES: all
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
    cpus: 8
    mem_limit: "20g"

  backend:
    build: ./backend
    ports:
      - "${BACKEND_PORT}:8000"
    volumes:
      - ./backend:/app
    depends_on:
      - ollama

    environment:
      - OLLAMA_API_ENDPOINT=http://ollama:11434
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_API_ENDPOINT=${OPENAI_API_ENDPOINT}
      - OPENAI_MODELS=${OPENAI_MODELS}
      - OLLAMA_MODELS=${OLLAMA_MODELS}

  frontend:
    build: ./frontend
    ports:
      - "${FRONTEND_PORT}:8501"
    volumes:
      - ./frontend:/app
    depends_on:
      - backend
    environment:
      - BACKEND_ENDPOINT=http://backend:8000
    command: ["streamlit", "run", "app.py"]
    
  db:
    build:
      context: ./db
      dockerfile: Dockerfile
    env_file:
      - .env
    volumes:
      - db-data:/var/lib/postgresql/data
    ports:
      - "5432:5432"  # Publish container's port 5432 to host's port 5432

volumes:
  db-data: